# =============================================================================
# Docker Compose - 기본 인프라만 실행 (Ollama + Qdrant)
# =============================================================================
# 사용법:
#   1. docker-compose up -d        # 백그라운드 실행
#   2. 모델 다운로드 완료 대기 (ollama healthcheck 확인)
#   3. scripts/run-rag-app.bat 실행  # RAG 앱 수동 시작
# =============================================================================

services:
  # Ollama 서비스 - AI 모델 서버
  ollama:
    build:
      context: ./ollama
      dockerfile: Dockerfile
    container_name: ollama
    ports:
      - "11434:11434"  # Ollama API 포트
    volumes:
      - ollama_data:/root/.ollama  # 모델 데이터 영구 저장
    restart: unless-stopped
    
    # 헬스체크: 모델 다운로드 완료 확인
    healthcheck:
      test: ["CMD-SHELL", "test -f /tmp/models_ready"]
      interval: 10s      # 체크 간격
      timeout: 5s        # 타임아웃
      retries: 60        # 최대 재시도 (총 10분)
      start_period: 30s  # 초기 대기 시간
    
    # 환경 설정
    environment:
      - OLLAMA_ORIGINS=*  # CORS 설정
    
    # 로그 설정
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Qdrant 서비스 - 벡터 데이터베이스
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"  # REST API 포트
      - "6334:6334"  # gRPC 포트
    volumes:
      - qdrant_storage:/qdrant/storage  # 벡터 데이터 영구 저장
    restart: unless-stopped
    
    # 헬스체크: Qdrant 서비스 준비 확인
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:6333/health || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 15s
    
    # 로그 설정
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# 네임드 볼륨 정의
volumes:
  ollama_data:
    driver: local
  qdrant_storage:
    driver: local

# 기본 네트워크 설정
networks:
  default:
    name: ai-project_default
    driver: bridge
